# -*- coding: utf-8 -*-
"""create_simple_qa_on_textfile_using_assistant_thread_run.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12znQE1qDVB6OU31px9nseGsJdMO7wdRJ

Create a simple QA(Question Answer) on Text File with following steps
- upload file to openai storage
- create own assistant
- create thread
- add messages to thread
- create run
- get result from opean ai
"""



# install dependencies
!pip install openai

# load dependencies
from openai import OpenAI

# connect with openai
client = OpenAI(api_key=api_key = "api-id")
client

# upload file to openai storage
# get file id
uploaded_file = client.files.create(
    file=open("story.txt",'rb'),
    purpose='assistants'
)
uploaded_file

# create own assistant
# mentioning file id and get assistant id
assistant = client.beta.assistants.create(
    name="Story helper",
    instructions="You are a motivator who answers the question based on the story file",
    tools=[{"type": "retrieval"}],
    model="gpt-4-turbo-preview",
    file_ids=[uploaded_file.id]
)
assistant

# Assistant(id='asst_VaRmvfp30jPvLuVJgYzxGmXf',
#           created_at=1709224786,
#           description=None,
#           file_ids=['file-qEkiCPGFrAS8OLc22fc8dsJN'],
#           instructions='You are a motivator who answers the question based on the story file',
#           metadata={}, model='gpt-4-turbo-preview',
#           name='Story helper',
#           object='assistant',
#           tools=[ToolRetrieval(type='retrieval')])

# to begin interaction we need to crate threads
# get thread id
thread = client.beta.threads.create()
thread

# add message to thread
message = client.beta.threads.messages.create(
    thread_id=thread.id,
    role="user",
    content="Who is the hero of the story?"
)
message

# for the assistant to respond to the user we need to create the run
run = client.beta.threads.runs.create(
  thread_id=thread.id,
  assistant_id=assistant.id
)
run

# to check the status of run
run = client.beta.threads.runs.retrieve(
  thread_id=thread.id,
  run_id=run.id
)
run.status

# get messages/result from openai
messages = client.beta.threads.messages.list(thread_id=thread.id)
messages

# run when status is completed to get the response
# from openai
while True:
    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)
    if run.status=="completed":
        messages = client.beta.threads.messages.list(thread_id=thread.id)
        latest_message = messages.data[0]
        text = latest_message.content[0].text.value
        print(text)
        break;

